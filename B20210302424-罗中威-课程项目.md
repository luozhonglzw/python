# 《Python程序设计基础》程序设计作品说明书

题目： Python爬虫项目

学院： 21计科04

姓名： 罗中威

学号： B20210302424

指导教师： 周景

起止日期：2023.11.10-2023.12.10

## 摘要

_介绍本次设计完成的项目的概述，本文的主要内容，总结你主要完成的工作以及关键词。_

关键词：

## 第1章 需求分析

_本章的内容主要包括系统的需求分析，系统主要需要实现的功能有哪些，可以帮助用户解决哪些问题等等。_
项目需求分析：

本爬虫项目的主要目标是爬取指定网站的标题，并将爬取到的标题转换为Excel文档形式存储。通过该系统，用户可以方便地获取目标网站的所有标题信息，并将这些信息进行整理和分析。

具体需求包括：

1. 爬取指定网站的所有标题信息；
2. 将标题信息存储为Excel文档形式；
3. 可定制爬取的网站和数据存储路径；
4. 可选择需要爬取的标题标签；
5. 支持多线程或异步爬取，以提高效率；
6. 可视化界面，方便用户操作。

该系统可以帮助用户解决以下问题：

1. 手动查询和整理网站标题费时费力；
2. 需要对爬取的数据进行整理和分析；
3. 需要可定制的爬取任务和数据存储方式；
4. 需要快速、高效地获取网站标题信息。


## 第2章 分析与设计

_本章的内容主要包括系统的设计，例如：系统架构、系统流程、系统模块、数据库的设计，以及关键的实现，例如：使用的数据结果、算法。_

系统分析与设计：

1. 系统架构：本系统采用基于Python的多线程或异步爬虫架构，包括数据爬取、数据处理和数据存储三个主要模块。数据爬取模块负责发送HTTP请求并解析网页内容，数据处理模块将解析到的标题信息转换为Excel文档形式，数据存储模块负责将转换后的Excel文档保存到指定路径。
2. 系统流程：系统流程包括以下步骤：发送HTTP请求、解析网页内容、筛选需要的标题标签、将标题信息保存为Excel文档形式、将Excel文档保存到指定路径。在爬取过程中，可以采用多线程或异步方式发送HTTP请求和解析网页内容，以提高效率。
3. 系统模块：系统主要包括数据爬取模块、数据处理模块和数据存储模块。数据爬取模块包括发送HTTP请求和解析网页内容两个子模块，数据处理模块包括筛选需要的标题标签和将标题信息转换为Excel文档形式两个子模块，数据存储模块包括将转换后的Excel文档保存到指定路径一个子模块。
4. 数据库的设计：本系统不需要建立数据库，因为数据都是临时存储的，不需要长期保存。在爬取过程中，可以使用Python内置的数据结构（如列表、字典等）来存储和传递数据。
5. 关键的实现：本系统的关键实现包括使用requests库发送HTTP请求、使用BeautifulSoup库解析网页内容、使用pandas库将数据转换为Excel文档形式等。在实现过程中，需要注意处理异常和错误情况，以保证系统的稳定性和可靠性。


## 第3章 软件测试

_本章的内容主要包括以类和函数作为单元进行单元测试，编写的对系统的主要功能的测试用例，以及测试用例执行的测试报告。_

配置python的环境：python3.9 pycharm

设置python代码：

```python

from lxml import html
import pandas as pd
import requests

# TODO 请注意pip install lxml,pip install pandas,pip install requests

etree = html.etree


cookies = {
    '__bid_n': '18531ea3ed0f67ec684207',
    'FEID': 'v10-12fc69002d8104a9445d7476b0747bd5dbf78c9b',
    'Hm_lvt_f4fa5d56f272ae0a0777feec2184a97f': '1671538836,1671960420,1671966884',
    'https_waf_cookie': 'af41f064-3687-44e2864c7f82b19af8ef8df3fdc898733ba9',
    'XSRF-TOKEN': 'eyJpdiI6IjdWWTBoVU9rYUpBMlpSdjFhYkdYSmc9PSIsInZhbHVlIjoiYjJKeW5PUk05cGQ0eSt5bU12T1ZWRzZDSzBkSWUwTWpSUUlrZDh5YXkwekVkOEpIbWNQbHMremJGNEl1WUJnUSIsIm1hYyI6IjdjZDgzOWExODg4YzFhNzU1MjEzNTY3YmQ0YTkxM2RlNzFmYTdhMzAzODQ1YzNiYjc3YTFhMTY3MzJjYTY1MzMifQ%3D%3D',
    'laravel_session': 'qj2hpVK86akiUDfsykT2j3Y3oVgYeoDppJd7QZQq',
}

headers = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Accept-Language': 'zh-CN,zh;q=0.9',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    # 'Cookie': '__bid_n=18531ea3ed0f67ec684207; FEID=v10-12fc69002d8104a9445d7476b0747bd5dbf78c9b; Hm_lvt_f4fa5d56f272ae0a0777feec2184a97f=1671538836,1671960420,1671966884; https_waf_cookie=af41f064-3687-44e2864c7f82b19af8ef8df3fdc898733ba9; XSRF-TOKEN=eyJpdiI6IjdWWTBoVU9rYUpBMlpSdjFhYkdYSmc9PSIsInZhbHVlIjoiYjJKeW5PUk05cGQ0eSt5bU12T1ZWRzZDSzBkSWUwTWpSUUlrZDh5YXkwekVkOEpIbWNQbHMremJGNEl1WUJnUSIsIm1hYyI6IjdjZDgzOWExODg4YzFhNzU1MjEzNTY3YmQ0YTkxM2RlNzFmYTdhMzAzODQ1YzNiYjc3YTFhMTY3MzJjYTY1MzMifQ%3D%3D; laravel_session=qj2hpVK86akiUDfsykT2j3Y3oVgYeoDppJd7QZQq',
    'Pragma': 'no-cache',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Sec-Fetch-User': '?1',
    'Upgrade-Insecure-Requests': '1',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'sec-ch-ua': '"Google Chrome";v="119", "Chromium";v="119", "Not?A_Brand";v="24"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Windows"',
}

response = requests.get('https://www.douguo.com/fenlei', cookies=cookies, headers=headers)


html_data = etree.HTML(response.text)

title_first_list = html_data.xpath('//div[@id="content"]/h2')

title_second_data_list = html_data.xpath('//div[@id="content"]/div[@class="clearfix"]')
list_all = []
for i in range(len(title_first_list)):
    title_first = ''.join(title_first_list[i].xpath('./text()'))
    title_second_list = title_second_data_list[i].xpath('./div')
    for data2 in title_second_list:
        title_second = ''.join(data2.xpath('./h2/text()'))
        title_third_list = data2.xpath('./ul[@class="sortlist clearfix"]/li')
        for data3 in title_third_list:
            title_third = ''.join(data3.xpath('./a/text()'))
            if title_third != '':
                list_all.append([title_first, title_second, title_third])

list_all = pd.DataFrame(list_all)
list_all.columns = ['第一级标题', '第二级标题', '第三极标题']
list_all.to_excel('./豆果菜谱分类' +'.xlsx')

```

测试的环境：https://www.douguo.com/fenlei 一个网站

测试的结果：将该网站 https://www.douguo.com/fenlei 中的一级标题，二级标题，三级标题 都写入xlsx文件中

![img.png](img.png)

## 结论

_本章的内容主要是对项目的总结，项目主要实现了哪些功能，达到了哪些目标，哪些不足之处，可以如何改进。_

python项目的实现较为简单，但是可以帮忙加深对于python语法的认识与数据结构的认识 对于python项目有了更深的理解

## 参考文献

《python爬虫项目》
